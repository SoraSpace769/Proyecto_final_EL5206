{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Proyecto Final Área de Imágenes\n",
    "### EL5206 Laboratorio de Inteligencia Computacional y Robótica\n",
    "\n",
    "Integrantes:\n",
    "* José Díaz\n",
    "* Luis Jiménez"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "El proyecto a realizar consiste en el desarrollo e implementación de un\n",
    "algoritmo de búsqueda de imágenes del tipo CBIR, el cual hará comparaciones entre\n",
    "una imagen de consulta e imágenes en la base de datos INRIA Holidays dataset a través de sus vectores de características.\n",
    "Para esta implementación se utilizarán dos extractores: uno clásico (HOG) y otro\n",
    "basado en redes convolucionales (CNN).\n",
    "\n",
    "Nota: con el fin de que el código funcione, todas las imágenes de la base de datos se almacenan\n",
    "en la carpeta JPG, que está en el mismo directorio que este notebook Jupyter."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Librerías útiles\n",
    "\n",
    "Carga de librerías útiles para el desarrollo del proyecto."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Extracción de características\n",
    "\n",
    "Para la extracción de carecterísticas se utilizará la función FEATURE_EXTRACTOR,\n",
    "que extrae el vector de características de una imagen, utilizando el extractor\n",
    "de tipo HOG  (clásico) o tipo CNN (red neuronal).\n",
    "\n",
    "Los parámetros que se le entregan a la función son el directorio de\n",
    "la imagen o imágenes (PATH_LIST), un directorio de guardado (SAVE_PATH)\n",
    "y el tipo de extractor (EXTRACTOR_TYPE). Cada vector de características\n",
    "asociado a una imagen se guarda en el directorio de guardado en forma de un\n",
    "archivo binario de formato .npy, el cual puede ser recuperado como array de Numpy\n",
    "mediante la función np.load.\n",
    "\n",
    "Hay que precisar que los directorios donde se guardarán los vectores de\n",
    "características deben estar ya creados para que el código funcione, por lo\n",
    "que en el mismo directorio de este notebook se requieren 2 carpetas: JPG_HOG para\n",
    "los vectores extraídos con el método HOG, y JPG_CNN para la extracción\n",
    "con CNN."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def feature_extractor(path_list, save_path, extractor_type):\n",
    "\n",
    "    if type(path_list) != type([]):\n",
    "        path_list = [path_list]\n",
    "\n",
    "    if extractor_type == 'HOG':\n",
    "\n",
    "        for file in tqdm(path_list):\n",
    "            image = Image.open(file)\n",
    "            image = image.resize((224,224))\n",
    "\n",
    "            hog_vect = hog(image, orientations=16, pixels_per_cell=(8, 8),\n",
    "                            cells_per_block=(1, 1), feature_vector=True, multichannel=True)\n",
    "\n",
    "            vect_name = vect_name = os.path.join(save_path, 'hog_' + os.path.basename(file[:-4]))\n",
    "            #print(type(hog_vect))\n",
    "            #print(hog_vect.shape)\n",
    "            np.save(vect_name, hog_vect)\n",
    "\n",
    "\n",
    "    elif extractor_type == 'CNN':\n",
    "\n",
    "        model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
    "        model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "\n",
    "        preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "         # create a mini-batch as expected by the model\n",
    "\n",
    "\n",
    "        # move the input and model to GPU for speed if available\n",
    "        if torch.cuda.is_available():\n",
    "            input_batch = input_batch.to('cuda')\n",
    "            model.to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for file in tqdm(path_list):\n",
    "                image = Image.open(file)\n",
    "                image = image.resize((224,224))\n",
    "                input_tensor = preprocess(image)\n",
    "                input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "                output = model(input_batch)\n",
    "                output = output.numpy().ravel()\n",
    "                vect_name = os.path.join(save_path, 'cnn_' + os.path.basename(file[:-4]))\n",
    "                #print(type(hog_vect))\n",
    "                #print(hog_vect.shape)\n",
    "                np.save(vect_name, output)\n",
    "\n",
    "    else:\n",
    "        print('Unknown extractor, please use either \"HOB\" or \"CNN\"')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Lista de directorios de todas las imágenes de la BBDD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "file_paths = [os.path.join('jpg', file) for file in os.listdir('jpg')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Extracción usando HOG"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1491.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6629b4ad8824a8e95a5ed264b660e55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "feature_extractor(file_paths, 'jpg_hog/', 'HOG')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Extracción usando CNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Luis Jiménez/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'resnext50_32x4d' from 'torchvision.models.resnet' (c:\\users\\luis jiménez\\desktop\\importante\\u\\lab_inteligencia\\proyecto\\proyecto_final_el5206\\venv\\lib\\site-packages\\torchvision\\models\\resnet.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-d80234e7938a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mfeature_extractor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile_paths\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'jpg_cnn/'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'CNN'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-2-4c40bba6b55e>\u001B[0m in \u001B[0;36mfeature_extractor\u001B[1;34m(path_list, save_path, extractor_type)\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mextractor_type\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'CNN'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m         \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhub\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'pytorch/vision:v0.6.0'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'resnet18'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpretrained\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m         \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mSequential\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\luis jiménez\\desktop\\importante\\u\\lab_inteligencia\\proyecto\\proyecto_final_el5206\\venv\\lib\\site-packages\\torch\\hub.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(repo_or_dir, model, *args, **kwargs)\u001B[0m\n\u001B[0;32m    368\u001B[0m         \u001B[0mrepo_or_dir\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_get_cache_or_reload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrepo_or_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mforce_reload\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 370\u001B[1;33m     \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_load_local\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrepo_or_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    371\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    372\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\luis jiménez\\desktop\\importante\\u\\lab_inteligencia\\proyecto\\proyecto_final_el5206\\venv\\lib\\site-packages\\torch\\hub.py\u001B[0m in \u001B[0;36m_load_local\u001B[1;34m(hubconf_dir, model, *args, **kwargs)\u001B[0m\n\u001B[0;32m    394\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    395\u001B[0m     \u001B[0mhubconf_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhubconf_dir\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mMODULE_HUBCONF\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 396\u001B[1;33m     \u001B[0mhub_module\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimport_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mMODULE_HUBCONF\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhubconf_path\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    397\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    398\u001B[0m     \u001B[0mentry\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_load_entry_from_hubconf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhub_module\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\luis jiménez\\desktop\\importante\\u\\lab_inteligencia\\proyecto\\proyecto_final_el5206\\venv\\lib\\site-packages\\torch\\hub.py\u001B[0m in \u001B[0;36mimport_module\u001B[1;34m(name, path)\u001B[0m\n\u001B[0;32m     69\u001B[0m     \u001B[0mmodule\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimportlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodule_from_spec\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m     \u001B[1;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mspec\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mLoader\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 71\u001B[1;33m     \u001B[0mspec\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexec_module\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodule\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     72\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Python39\\lib\\importlib\\_bootstrap_external.py\u001B[0m in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "\u001B[1;32mC:\\Python39\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "\u001B[1;32m~/.cache\\torch\\hub\\pytorch_vision_v0.6.0\\hubconf.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdensenet\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdensenet121\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdensenet169\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdensenet201\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdensenet161\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minception\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0minception_v3\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresnet\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mresnet18\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresnet34\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresnet50\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresnet101\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresnet152\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m     \u001B[0mresnext50_32x4d\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresnext101_32x8d\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwide_resnet50_2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwide_resnet101_2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueezenet\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msqueezenet1_0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msqueezenet1_1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'resnext50_32x4d' from 'torchvision.models.resnet' (c:\\users\\luis jiménez\\desktop\\importante\\u\\lab_inteligencia\\proyecto\\proyecto_final_el5206\\venv\\lib\\site-packages\\torchvision\\models\\resnet.py)"
     ]
    }
   ],
   "source": [
    "feature_extractor(file_paths, 'jpg_cnn/', 'CNN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Métricas\n",
    "\n",
    "Se definen métricas de comparación entre vectores de\n",
    "características de imágenes, correspondientes a distancia entre\n",
    "vectores."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Distancia euclideana"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def dist_euc(X, Y):\n",
    "\n",
    "    dist = np.linalg.norm(X-Y)\n",
    "    return dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Distancia chi-cuadrado [1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def dist_chi2(X, Y):\n",
    "\n",
    "    chi = 0.5 * np.sum([((x - y) ** 2) / (x + y)\n",
    "                      for (x, y) in zip(X, Y)])\n",
    "    return chi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Pruebas de dist_euc y dist_chi2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.928203230275509 3.133333333333333\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2,3])\n",
    "Y = np.array([5,6,7])\n",
    "print(dist_euc(X, Y), dist_chi2(X, Y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Función para elegir tipo de distancia"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def dist_vectors(X, Y, dist_type):\n",
    "\n",
    "    if dist_type == 'euc':\n",
    "\n",
    "        dist = dist_euc(X, Y)\n",
    "\n",
    "    elif dist_type == 'chi2':\n",
    "\n",
    "        dist = dist_chi2(X, Y)\n",
    "\n",
    "    return dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Comparación de una imagen de consulta con la BBDD\n",
    "\n",
    "En esta sección, para cada imagen de consulta, se calcula la distancia entre\n",
    "su vector de características con todos los vectores de características de\n",
    "la base de datos.\n",
    "\n",
    "1 + CLASE (3d) + ID_imagen (2d)\n",
    "\n",
    "RECORDATORIO: ID_imagen = 00 -> CONSULTA\n",
    "\n",
    "DISTINTO DE 00 ES BBDD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Separación entre grupo de consulta y grupo de BBDD"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1491.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6406ed6da0b4e0780b57463fd623e5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w_path = 'jpg_hog/'\n",
    "img_query = []\n",
    "query_names = []\n",
    "img_db = []\n",
    "db_names = []\n",
    "\n",
    "for file in tqdm(os.listdir(w_path)):\n",
    "\n",
    "    vector_path = w_path + file\n",
    "    feat_vector = np.load(vector_path)\n",
    "    ID_image = vector_path[-6:-4]\n",
    "\n",
    "    if ID_image == '00':\n",
    "        img_query.append(feat_vector)\n",
    "        query_names.append(file[-10:-4])\n",
    "\n",
    "    else:\n",
    "        img_db.append(feat_vector)\n",
    "        db_names.append(file[-10:-4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cálculo de distancias entre imagen de consulta e imágenes de la BBDD\n",
    "\n",
    "Sintaxis:\n",
    "*   distances_euc{'nombre_img_consulta'} = vector_distancias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#uso distancia euclideana\n",
    "distances_euc = {}\n",
    "for i in range(len(img_query)):\n",
    "\n",
    "    query_vect = img_query[i]\n",
    "    query_name = query_names[i]\n",
    "    distances = []\n",
    "\n",
    "    for j in range(len(img_db)):\n",
    "\n",
    "        distances.append(dist_vectors(query_vect, img_db[j],\n",
    "                                      dist_type = 'euc'))\n",
    "\n",
    "    distances_euc[query_name] = np.array(distances)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Ordenamiento de imágenes por relevancia (medida de Ranking)\n",
    "\n",
    "A continuación, para cada imagen de consulta, se ordenan de menor a mayor\n",
    "las distancias obtenidas al hacer la comparación con la base de datos.\n",
    "Adicionalmente, se conservan los índices de las distancias previo al\n",
    "ordenamiento, ya que dichos índices corresponden a las imágenes de la\n",
    "base de datos, que se necesitarán para la medida de ranking.\n",
    "\n",
    "Sintaxis:\n",
    "*   dist_sort_euc{'nombre_img_consulta'} = vector_distancias\n",
    "*   dist_sort_euc_index{'nombre_img_consulta'} = pos_previas_dist\n",
    "\n",
    "para cada imagen \"query\",\n",
    "calculaba sus distancias con todas las imagenes en la\n",
    "base de datos, las ordenaba, y calculaba el ranking\n",
    "sacando el promedio de la posición en que quedaron\n",
    "las imágenes de la misma clase a la query"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#uso distancia euclideana\n",
    "dist_sort_euc = {}\n",
    "dist_sort_euc_index = {}\n",
    "img_query_names = list(distances_euc.keys())\n",
    "\n",
    "for i in range(len(distances_euc)):\n",
    "\n",
    "    dist_vector = distances_euc[img_query_names[i]]\n",
    "    dist_vector_index = np.argsort(dist_vector)\n",
    "    dist_vector_sort = np.sort(dist_vector)\n",
    "    dist_sort_euc[img_query_names[i]] = dist_vector_sort\n",
    "    dist_sort_euc_index[img_query_names[i]] = dist_vector_index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Luego, con las imágenes ordenadas, se calcula una medida de ranking,\n",
    "que entrega la posición promedio de las imágenes que entrega el buscador\n",
    "al realizar la consulta de una imagen.\n",
    "\n",
    "Las imágenes consideradas relevantes para la consulta de una imagen particular\n",
    "corresponden a imágenes de la base de datos que pertenecen a la misma\n",
    "clase que la imagen de consulta.\n",
    "\n",
    "La función que se muestra a continuación calcula el ranking para\n",
    "una sola imagen de consulta, además del número de imágenes relevantes\n",
    "para la consulta en curso."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def rank(img_query_name, rel_pos = False):\n",
    "\n",
    "    Nrel = 0\n",
    "    sum = 0\n",
    "    img_query_class = img_query_name[1:2]\n",
    "    img_db_pos = dist_sort_euc_index[img_query_name]\n",
    "    relevant_pos = []\n",
    "\n",
    "    for pos in img_db_pos:\n",
    "\n",
    "        img_db_class = db_names[pos][1:2]\n",
    "\n",
    "        if img_db_class == img_query_class:\n",
    "\n",
    "            sum += pos\n",
    "            Nrel += 1\n",
    "            relevant_pos.append(pos)\n",
    "\n",
    "    r = sum/Nrel\n",
    "    r_pos = np.array(relevant_pos)\n",
    "\n",
    "    if rel_pos == True:\n",
    "        return r, Nrel, r_pos\n",
    "\n",
    "    else:\n",
    "        return r, Nrel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Comparación de métodos de extracción\n",
    "\n",
    "Se necesita evaluar la robustez de los métodos de extracción utilizados\n",
    "en este proyecto, y una forma de compararlos es mediante la normalización\n",
    "de la medida de Ranking que se utilizó anteriormente."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def rank_norm(img_query_name):\n",
    "\n",
    "    r, Nrel = rank(img_query_name)\n",
    "    N = len(db_names)\n",
    "\n",
    "    r_norm = (r*Nrel - (Nrel(Nrel + 1))/2) * (N*Nrel)**(-1)\n",
    "\n",
    "    return r_norm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6. Ejemplos de uso del algoritmo\n",
    "\n",
    "A continuación se muestran algunos ejemplos de consulta de imágenes\n",
    "y la respuesta del método, cambiando tipos de extractores y métricas\n",
    "de distancias utilizadas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7. Optimización algorítmica del método"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Referencias utilizadas\n",
    "\n",
    "[1] https://www.geeksforgeeks.org/chi-square-distance-in-python/\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}